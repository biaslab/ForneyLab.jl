{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Variational Inference for a Softmax Model\n",
    "\n",
    "The local variational method can be extended to multidimensional models by use of the softmax function (see e.g. Ahmed, 2013). In this demo we consider the following model:\n",
    "\n",
    "\\begin{align*}\n",
    "    s &\\sim \\mathcal{N}(m_s, V_s)\\\\\n",
    "    p_i &\\sim \\mathcal{N}(A_i \\cdot s, I_2)\\\\\n",
    "    y_i &\\sim \\mathcal{C}at(\\sigma(p_i))\\,,\n",
    "\\end{align*}\n",
    "\n",
    "where $A_i$ is a matrix that encodes the lineup and winner/loser for encounter $i$, and with $\\sigma$ a softmax. We are interested in estimating a belief over player strength. In this demo, we use the softmax to implement a \"greater than\" constraint as used in the example from Infer.NET, 2020, see references. The example consists of a number of match results in head-to-head encounters between 5 players being used to estimate their (relative) skills, including an estimate of the uncertainty on each skill. This notebook was developed by Keith Myerscough of Sioux LIME, lending heavily from other notebooks in this demo folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "using ForneyLab\n",
    "using PyPlot\n",
    "using LinearAlgebra\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 beats 2\n",
      "1 beats 4\n",
      "1 beats 5\n",
      "2 beats 3\n",
      "4 beats 2\n",
      "5 beats 3\n"
     ]
    }
   ],
   "source": [
    "# Generate data set\n",
    "Random.seed!(21)\n",
    "σ(x) = exp.(x)/sum(exp.(x)) # Softmax function\n",
    "\n",
    "n_players = 5\n",
    "winners = [1, 1, 1, 2, 4, 5]\n",
    "losers = [2, 4, 5, 3, 2, 3]\n",
    "n_matches = length(winners)\n",
    "\n",
    "# Define matrices for match outcomes\n",
    "A = [zeros(2, n_players) for _ in 1:n_matches]\n",
    "for i_m = 1:n_matches\n",
    "    println(\"$(winners[i_m]) beats $(losers[i_m])\")\n",
    "    A[i_m][1, winners[i_m]] = 1 # The first row of A_i always encodes the winner\n",
    "    A[i_m][2, losers[i_m]] = 1\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model specification\n",
    "\n",
    "The model specification includes local variational parameters `xi` and `a`, which are used to define an upperbound on the softmax (Bouchard, 2007)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = FactorGraph()\n",
    "\n",
    "perf_prec = 1.0\n",
    "m_s_prior = 6.0*ones(n_players)\n",
    "v_s_prior = 9.0*eye(n_players)\n",
    "\n",
    "@RV s ~ GaussianMeanVariance(m_s_prior, v_s_prior)\n",
    "\n",
    "p = Vector{Variable}(undef, n_matches)\n",
    "xi = Vector{Variable}(undef, n_matches)\n",
    "a = Vector{Variable}(undef, n_matches)\n",
    "y = Vector{Variable}(undef, n_matches)\n",
    "for i_m = 1:n_matches\n",
    "    @RV p[i_m] ~ GaussianMeanPrecision(A[i_m]*s, perf_prec*eye(2))\n",
    "    @RV xi[i_m]\n",
    "    @RV a[i_m]\n",
    "    @RV y[i_m] ~ Softmax(p[i_m], xi[i_m], a[i_m])\n",
    "\n",
    "    placeholder(y[i_m], :y, index=i_m, dims=(2,))\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm generation\n",
    "\n",
    "Since we are interested in optimizing the local variational parameters `xi`, `a` together with the hidden state sequence `x`, we construct an algorithm that also updates `xi` and `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = PosteriorFactorization(s, p, xi, a, ids=[:S, :P, :Xi, :A])\n",
    "algo = messagePassingAlgorithm(s, q)\n",
    "source_code = algorithmSourceCode(algo);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# println(source_code) # Uncomment to inspect algorithm code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution\n",
    "\n",
    "For execution we initialize the local variational parameters and iterate the automatically derived algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(Meta.parse(source_code));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-initialize marginals\n",
    "marginals = Dict()\n",
    "marginals[:s] = ProbabilityDistribution(Multivariate, GaussianMeanVariance, m=m_s_prior, v=v_s_prior)\n",
    "for t=1:n_matches\n",
    "    marginals[:p_*t] = ProbabilityDistribution(Multivariate, GaussianMeanVariance, m=m_s_prior[1]*ones(2), v=v_s_prior[1, 1]*eye(2))\n",
    "    marginals[:xi_*t] = ProbabilityDistribution(Multivariate, GaussianMeanPrecision, m=ones(2), w=eye(2))\n",
    "    marginals[:a_*t] = ProbabilityDistribution(Univariate, GaussianMeanPrecision)\n",
    "end\n",
    "\n",
    "# Prepare data dictionary\n",
    "# We encoded A_i so that the player encoded by the first row of A_i is always the winner\n",
    "data = Dict(:y  => [[1, 0] for _ in 1:n_matches])\n",
    "\n",
    "# Execute algorithm\n",
    "n_its = 100\n",
    "for i = 1:n_its\n",
    "    stepA!(data, marginals)\n",
    "    stepXi!(data, marginals) # Update local variational parameters\n",
    "    stepS!(data, marginals) # Update hidden state\n",
    "    stepP!(data, marginals) # Update hidden state\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Results show that the algorithm accurately estimates the hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player 1 with rating 9.678 ± 0.567\n",
      "player 2 with rating 4.879 ± 0.567\n",
      "player 3 with rating 2.637 ± 0.688\n",
      "player 4 with rating 6.692 ± 0.688\n",
      "player 5 with rating 6.072 ± 0.688\n"
     ]
    }
   ],
   "source": [
    "# Extract posterior state statistics\n",
    "m_s = [mean(marginals[:s])[j_p] for j_p = 1:n_players]\n",
    "v_s = [cov(marginals[:s])[j_p, j_p] for j_p = 1:n_players]\n",
    "\n",
    "for j_p = 1:n_players\n",
    "    println(\"player $(j_p) with rating $(round(m_s[j_p],digits=3)) ± $(round(sqrt.(v_s[j_p]),digits=3))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing to Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is compared to that of Infer.NET, 2020:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer.NET reference values\n",
    "ref_mean = [9.517, 4.955, 2.639, 6.834, 6.054]\n",
    "ref_dev = [3.926, 3.503, 4.288, 3.892, 4.731]\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, while the esimated skills are very close to the reference of Infer.NET, the variances are not. This might be due to the current results being based on Variational Message Passing, while Infer.NET uses Expectation Propagation. VMP is known to exhibit mode-seeking behaviour, usually leading to an under-estimation of the variance. In contrast, EP exhibits mode-covering behaviour, generally over-estimating the variance. Expectation propagation for the `SoftMax` node is not yet implemented in ForneyLab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Bouchard, 2007 \"Efficient Bounds for the Softmax Function\"\n",
    "\n",
    "Ahmed, 2013, \"Bayesian Multicategorical Soft Data Fusion for Human-Robot Collaboration\"\n",
    "\n",
    "Infer.NET, 2020, https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/matchup-app-infer-net"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
